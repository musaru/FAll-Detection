{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "SN-DTG2Rc7qy"
   },
   "outputs": [],
   "source": [
    "#SDFA-Structure-Aware-Discriminative-Feature-Aggregation-for-Efficient-Human-Fall-Detection-in-Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sgvyn61_dG_J"
   },
   "source": [
    "##Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3tix4bwrdHmy"
   },
   "outputs": [],
   "source": [
    "def import_class(name):\n",
    "    components = name.split('.')\n",
    "    mod = __import__(components[0])\n",
    "    for comp in components[1:]:\n",
    "        mod = getattr(mod, comp)\n",
    "    return mod\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    #return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for name, p in model.named_parameters() if p.requires_grad and 'fc' not in name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlTPcLWEdJPa"
   },
   "source": [
    "##Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kjpKQkB4dLqK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from model.activations import *\n",
    "def activation_factory(name, inplace=True):\n",
    "    if name == 'relu':\n",
    "        return nn.ReLU(inplace=inplace)\n",
    "    elif name == 'leakyrelu':\n",
    "        return nn.LeakyReLU(0.2, inplace=inplace)\n",
    "    elif name == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif name == 'swish':\n",
    "        return Swish()\n",
    "    elif name == 'hardswish':\n",
    "        return HardSwish()\n",
    "    elif name == 'metaacon':\n",
    "        return MetaAconC()\n",
    "    elif name == 'acon':\n",
    "        return AconC()\n",
    "    elif name == 'linear' or name is None:\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise ValueError('Not supported activation:', name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_MWZDqKdDY7"
   },
   "source": [
    "##Random Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ju0yWgyHdRKU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import warnings\n",
    "class Randomized_DropBlock_Ske(nn.Module):\n",
    "    def __init__(self, block_size=7):\n",
    "        super(Randomized_DropBlock_Ske, self).__init__()\n",
    "        self.keep_prob = 0.0\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, input, keep_prob, A, num_point):  # n,c,t,v\n",
    "        self.keep_prob = keep_prob\n",
    "        self.num_point = num_point\n",
    "        if not self.training or self.keep_prob == 1:\n",
    "            return input\n",
    "        n, c, t, v = input.size()\n",
    "        #print(input.shape) \n",
    "        input_abs = torch.mean(torch.mean(\n",
    "            torch.abs(input), dim=2), dim=1).detach()\n",
    "        input_abs = input_abs / torch.sum(input_abs) * input_abs.numel()\n",
    "        if self.num_point == 25:  # Kinect V2 \n",
    "            gamma = (1. - self.keep_prob) / (1 + 1.92)\n",
    "        elif self.num_point == 20:  # Kinect V1\n",
    "            gamma = (1. - self.keep_prob) / (1 + 1.9)\n",
    "        else:\n",
    "            gamma = (1. - self.keep_prob) / (1 + 1.92)\n",
    "            warnings.warn('undefined skeleton graph')\n",
    "        M_seed = torch.bernoulli(torch.clamp(\n",
    "            input_abs * gamma, max=1.0)).to(device=input.device, dtype=input.dtype)\n",
    "        #print(M_seed.shape)\n",
    "        print(A.shape)\n",
    "        M = torch.matmul(M_seed, A)\n",
    "        #M = torch.einsum('nv,cvw->nv', (M_seed, A)).contiguous()\n",
    "        M[M > 0.001] = 1.0\n",
    "        M[M < 0.5] = 0.0\n",
    "        #print(M.shape)\n",
    "        mask = (1 - M).view(n, 1, 1, self.num_point)\n",
    "        #print(M.shape)\n",
    "        return input * mask * mask.numel() / mask.sum()\n",
    "    \n",
    "    \n",
    "class Randomized_DropBlockT_1d(nn.Module):\n",
    "    def __init__(self, block_size=7):\n",
    "        super(Randomized_DropBlockT_1d, self).__init__()\n",
    "        self.keep_prob = 0.0\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, input, keep_prob):\n",
    "        self.keep_prob = keep_prob\n",
    "        if not self.training or self.keep_prob == 1:\n",
    "            return input\n",
    "        n,c,t,v = input.size()\n",
    "\n",
    "        input_abs = torch.mean(torch.mean(torch.abs(input),dim=3),dim=1).detach()\n",
    "        input_abs = (input_abs/torch.sum(input_abs)*input_abs.numel()).view(n,1,t)\n",
    "        gamma = (1. - self.keep_prob) / self.block_size\n",
    "        input1 = input.permute(0,1,3,2).contiguous().view(n,c*v,t)\n",
    "        M = torch.bernoulli(torch.clamp(input_abs * gamma, max=1.0)).repeat(1,c*v,1)\n",
    "        Msum = F.max_pool1d(M, kernel_size=[self.block_size], stride=1, padding=self.block_size // 2)\n",
    "        idx = torch.randperm(Msum.shape[2])\n",
    "        RMsum = Msum[:,:,idx].view(Msum.size()) ## shuffles MSum to drop random frames instead of dropping a block of frames\n",
    "        mask = (1 - RMsum).to(device=input.device, dtype=input.dtype)\n",
    "        #print(mask.shape)\n",
    "        return (input1 * mask * mask.numel() /mask.sum()).view(n,c,v,t).permute(0,1,3,2)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "       \n",
    "    #dropS = DropBlock_Ske()\n",
    "    x = torch.randn(12,96,50,6)\n",
    "    #x = torch.randn(12,96,75,6)\n",
    "    A = torch.randn(3,6,25)\n",
    "\n",
    "    #out = dropS(x, 0.9, A, x.shape[3])\n",
    "    dropT = Randomized_DropBlockT_1d(block_size=41)\n",
    "    #dropT = DropBlockT_1d(block_size=41)\n",
    "    #mask, out = dropT(x, 0.9)\n",
    "    mask= dropT(x, 0.9)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ipw1Vu9dS19"
   },
   "source": [
    "##Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "bAyhsf_vdVHT"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Sep 12 23:53:06 2021\n",
    "@author: sania\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from model.activation import activation_factory\n",
    "#from model.Random_Drops import *\n",
    "\n",
    "# Thanks to YAN Sijie for the released code on Github (https://github.com/yysijie/st-gcn)\n",
    "class SpatialGraphConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, max_graph_distance, bias, edge, A, act_type, keep_prob, block_size, \n",
    "                 num_point, residual=True, **kwargs):\n",
    "        super(SpatialGraphConv, self).__init__()\n",
    "        self.keep_prob = keep_prob\n",
    "        self.num_point = num_point\n",
    "        self.s_kernel_size = max_graph_distance + 1\n",
    "        self.gcn = nn.Conv2d(in_channel, out_channel, 1, bias=bias)\n",
    "        self.A = nn.Parameter(A, requires_grad=False)\n",
    "        if edge:\n",
    "            self.edge = nn.Parameter(torch.ones_like(self.A))\n",
    "        else:\n",
    "            self.edge = 1\n",
    "            \n",
    "        self.act = activation_factory(act_type)   \n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        \n",
    "        if residual and in_channel != out_channel:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, 1, bias=bias),\n",
    "                nn.BatchNorm2d(out_channel),\n",
    "            )\n",
    "        self.dropS = Randomized_DropBlock_Ske()\n",
    "        self.dropT = Randomized_DropBlockT_1d(block_size=block_size)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        res = self.residual(x)\n",
    "        x = self.gcn(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        #x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n",
    "        print(self.A.shape)\n",
    "        print(self.edge.shape)\n",
    "        #print(x.shape)\n",
    "        x = torch.einsum('nctv,cvw->nctw', (x, self.A * self.edge)).contiguous()#n=バッチサイズ,1\n",
    "        #print(self.A * self.edge)\n",
    "        #x = self.dropS(self.bn(x), self.keep_prob, self.A * self.edge, self.num_point) + self.dropS(res, self.keep_prob, self.A * self.edge, self.num_point)\n",
    "        x = self.dropT(self.dropS(self.bn(x), self.keep_prob, self.A * self.edge, self.num_point), self.keep_prob) + self.dropT(self.dropS(res, self.keep_prob, self.A * self.edge, self.num_point), self.keep_prob)\n",
    "        \n",
    "        return self.act(x)\n",
    "    \n",
    "class SepTemporal_Block(nn.Module):\n",
    "    def __init__(self, channel, temporal_window_size, bias, act_type, edge, A, num_point, keep_prob, block_size, expand_ratio, stride=1, residual=True, **kwargs):\n",
    "        super(SepTemporal_Block, self).__init__()\n",
    "        self.keep_prob = keep_prob\n",
    "        self.num_point = num_point\n",
    "        padding = (temporal_window_size - 1) // 2\n",
    "        self.act = activation_factory(act_type)\n",
    "\n",
    "        if expand_ratio > 0:\n",
    "            inner_channel = channel * expand_ratio\n",
    "            self.expand_conv = nn.Sequential(\n",
    "                nn.Conv2d(channel, inner_channel, 1, bias=bias),\n",
    "                nn.BatchNorm2d(inner_channel),\n",
    "            )\n",
    "        else:\n",
    "            inner_channel = channel\n",
    "            self.expand_conv = None\n",
    "\n",
    "        self.depth_conv = nn.Sequential(\n",
    "            nn.Conv2d(inner_channel, inner_channel, (temporal_window_size,1), (stride,1), (padding,0), groups=inner_channel, bias=bias),\n",
    "            nn.BatchNorm2d(inner_channel),\n",
    "        )\n",
    "        self.point_conv = nn.Sequential(\n",
    "            nn.Conv2d(inner_channel, channel, 1, bias=bias),\n",
    "            nn.BatchNorm2d(channel),\n",
    "        )\n",
    "        if not residual:\n",
    "            self.residual = lambda x:0\n",
    "        elif stride == 1:\n",
    "            self.residual = nn.Identity()\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(channel, channel, 1, (stride,1), bias=bias),\n",
    "                nn.BatchNorm2d(channel),\n",
    "            )\n",
    "        self.A = nn.Parameter(A, requires_grad=False)\n",
    "        if edge:\n",
    "            self.edge = nn.Parameter(torch.ones_like(self.A))\n",
    "        else:\n",
    "            self.edge = 1\n",
    "        self.dropS = Randomized_DropBlock_Ske()\n",
    "        self.dropT = Randomized_DropBlockT_1d(block_size=block_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.residual(x)\n",
    "        if self.expand_conv is not None:\n",
    "            x = self.act(self.expand_conv(x))\n",
    "        x = self.act(self.depth_conv(x))\n",
    "        x = self.point_conv(x)\n",
    "        #x = self.dropT(x, self.keep_prob) + self.dropT(res, self.keep_prob)\n",
    "        x = self.dropT(self.dropS(x, self.keep_prob, self.A * self.edge, self.num_point), self.keep_prob) + self.dropT(self.dropS(res, self.keep_prob, self.A * self.edge, self.num_point), self.keep_prob)\n",
    "        return self.act(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEMKBVq1dW_c"
   },
   "source": [
    "##AdjGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "08LXqZbBdY7y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class adjGraph():\n",
    "    \"\"\" The Graph to model the skeletons extracted by the openpose\n",
    "    Args:\n",
    "        strategy (string): must be one of the follow candidates\n",
    "        - uniform: Uniform Labeling\n",
    "        - distance: Distance Partitioning\n",
    "        - spatial: Spatial Configuration\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        layout (string): must be one of the follow candidates\n",
    "        - openpose: Is consists of 18 joints. For more information, please\n",
    "            refer to https://github.com/CMU-Perceptual-Computing-Lab/openpose#output\n",
    "        - ntu-rgb+d: Is consists of 25 joints. For more information, please\n",
    "            refer to https://github.com/shahroudy/NTURGB-D\n",
    "        max_hop (int): the maximal distance between two connected nodes\n",
    "        dilation (int): controls the spacing between the kernel points\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 layout='ntu-rgb+d',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(\n",
    "            self.num_node, self.edge, max_hop=max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.A\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'openpose':\n",
    "            self.num_node = 18\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(4, 3), (3, 2), (7, 6), (6, 5), (13, 12), (12,\n",
    "                                                                        11),\n",
    "                             (10, 9), (9, 8), (11, 5), (8, 2), (5, 1), (2, 1),\n",
    "                             (0, 1), (15, 0), (14, 0), (17, 15), (16, 14)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 1\n",
    "        elif layout == 'ntu-rgb+d':\n",
    "            self.num_node = 25\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_1base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21),\n",
    "                              (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n",
    "                              (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n",
    "                              (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n",
    "                              (22, 23), (23, 8), (24, 25), (25, 12)]\n",
    "            neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 21 - 1\n",
    "        elif layout == 'ntu_edge':\n",
    "            self.num_node = 24\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_1base = [(1, 2), (3, 2), (4, 3), (5, 2), (6, 5), (7, 6),\n",
    "                              (8, 7), (9, 2), (10, 9), (11, 10), (12, 11),\n",
    "                              (13, 1), (14, 13), (15, 14), (16, 15), (17, 1),\n",
    "                              (18, 17), (19, 18), (20, 19), (21, 22), (22, 8),\n",
    "                              (23, 24), (24, 12)]\n",
    "            neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 2\n",
    "        # elif layout=='customer settings'\n",
    "        #     pass\n",
    "        elif layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "        else:\n",
    "            raise ValueError(\"Do Not Exist This Layout.\")\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[\n",
    "                                    i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.\n",
    "                                              center] > self.hop_dis[i, self.\n",
    "                                                                     center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "        else:\n",
    "            raise ValueError(\"Do Not Exist This Strategy\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \"\"\"The Graph to model the skeletons extracted by the Alpha-Pose.\n",
    "    Args:\n",
    "        - strategy: (string) must be one of the follow candidates\n",
    "            - uniform: Uniform Labeling,\n",
    "            - distance: Distance Partitioning,\n",
    "            - spatial: Spatial Configuration,\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        - layout: (string) must be one of the follow candidates\n",
    "            - coco_cut: Is COCO format but cut 4 joints (L-R ears, L-R eyes) out.\n",
    "        - max_hop: (int) the maximal distance between two connected nodes.\n",
    "        - dilation: (int) controls the spacing between the kernel points.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layout='coco_cut',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(self.num_node, self.edge, max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "        else:\n",
    "            raise ValueError('This layout is not supported!')\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.center] > self.hop_dis[i, self.center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "            #self.A = np.swapaxes(np.swapaxes(A, 0, 1), 1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"This strategy is not supported!\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPW9T-vpdajc"
   },
   "source": [
    "##Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "vIXsnqYrddw8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: command not found\n",
      "torch.Size([1, 14, 14])\n",
      "torch.Size([1, 14, 14])\n",
      "torch.Size([32, 128, 300, 14])\n",
      "torch.Size([32, 128, 300, 14])\n",
      "torch.Size([32, 128, 150, 14])\n",
      "torch.Size([1, 14, 14])\n",
      "torch.Size([1, 14, 14])\n",
      "torch.Size([32, 256, 150, 14])\n",
      "torch.Size([32, 256, 150, 14])\n",
      "torch.Size([32, 256, 75, 14])\n",
      "torch.Size([32, 256, 1050])\n",
      "torch.Size([32, 256])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from model.layers import *\n",
    "#from utils import import_class\n",
    "#from Utils import Graph\n",
    "\n",
    "class cnn1x1(nn.Module):\n",
    "    def __init__(self, dim1 = 3, dim2 =3, bias = True):\n",
    "        super(cnn1x1, self).__init__()\n",
    "        self.cnn = nn.Conv2d(dim1, dim2, kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        return x\n",
    "    \n",
    "class norm_data(nn.Module):\n",
    "    def __init__(self, dim= 64):\n",
    "        super(norm_data, self).__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(dim* 14) # dim * num_nodes\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, num_joints, step = x.size()\n",
    "        x = x.view(bs, -1, step)\n",
    "        x = self.bn(x)\n",
    "        x = x.view(bs, -1, num_joints, step).contiguous()\n",
    "        return x\n",
    "    \n",
    "class embed(nn.Module):\n",
    "    def __init__(self, dim, dim1, att_type, norm = True, bias = False):\n",
    "        super(embed, self).__init__()\n",
    "\n",
    "        if norm:\n",
    "            self.cnn = nn.Sequential(                        \n",
    "                norm_data(dim),\n",
    "                cnn1x1(dim, dim1, bias=bias),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.cnn = nn.Sequential(\n",
    "                cnn1x1(dim, dim1, bias=bias),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        #self.attention =  Attention_Layer(dim1,  att_type=att_type)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        #print(x.shape)\n",
    "        return x#self.attention(x)\n",
    "\n",
    "\n",
    "def init_param(modules):\n",
    "    for m in modules:\n",
    "        if isinstance(m, nn.Conv1d) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm3d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv3d) or isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, std=0.001)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_class,\n",
    "                 num_point,\n",
    "                 max_frame,\n",
    "                 graph,\n",
    "                 act_type, \n",
    "                 bias,\n",
    "                 edge,\n",
    "                 block_size):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.num_class =  num_class\n",
    "        temporal_window_size = 3\n",
    "        max_graph_distance = 2\n",
    "        keep_prob = 0.9\n",
    "        #Graph = import_class(graph)\n",
    "        Graph = graph\n",
    "        #A_binary = torch.Tensor(Graph().A_binary)\n",
    "        A_binary = torch.Tensor(Graph.A)\n",
    "        #A = torch.rand(3,25,25).cuda()#.to(num_class.dtype).to(num_class.device)\n",
    "        #self.graph_hop = adjGraph(**graph_args)\n",
    "        #A = torch.tensor(self.graph_hop.A, dtype=torch.float32, requires_grad=False)\n",
    "        #self.register_buffer('A', A)\n",
    "        \n",
    "        # channels\n",
    "        D_embed = 64\n",
    "        c1 = D_embed*2\n",
    "        c2 = c1 * 2     \n",
    "        #c3 = c2 * 2    \n",
    "       \n",
    "        \n",
    "        \n",
    "        self.joint_embed = embed(2, D_embed, att_type='stja', norm=True, bias=bias)\n",
    "        #self.dif_embed = embed(2, D_embed, att_type='stja', norm=True, bias=bias) #601\n",
    "        #self.attention =  Attention_Layer(D_embed,  max_frame, act_type, att_type='stja')\n",
    "        \n",
    "        self.sgcn1 = SpatialGraphConv(D_embed, c1, max_graph_distance, bias, edge, A_binary, act_type, keep_prob, block_size, num_point, residual=True)\n",
    "        self.tcn11 = SepTemporal_Block(c1, temporal_window_size, bias, act_type, edge, A_binary, num_point, keep_prob, block_size, expand_ratio=0, stride=1, residual=True)\n",
    "        self.tcn12 = SepTemporal_Block(c1, temporal_window_size+2, bias, act_type, edge, A_binary, num_point, keep_prob, block_size, expand_ratio=0, stride=2, residual=True)\n",
    "        \n",
    "        self.sgcn2 = SpatialGraphConv(c1, c2, max_graph_distance, bias, edge, A_binary, act_type, keep_prob, block_size, num_point, residual=True)\n",
    "        self.tcn21 = SepTemporal_Block(c2, temporal_window_size, bias, act_type, edge, A_binary, num_point, keep_prob, block_size, expand_ratio=0, stride=1, residual=True)\n",
    "        self.tcn22 = SepTemporal_Block(c2, temporal_window_size+2, bias, act_type, edge, A_binary, num_point, keep_prob, block_size, expand_ratio=0, stride=2, residual=True)\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(c2, num_class)\n",
    "        #init_param(self.modules())\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        \n",
    "        N, C, T, V = x.size()\n",
    "        #dy = x\n",
    "        \n",
    "        # Dynamic Representation        \n",
    "        pos = x.permute(0, 1, 3, 2).contiguous()  # N, C, V, T\n",
    "        #print(pos.shape):torch.Size([1, 2, 25, 300])\n",
    "        #dif = pos[:, :, :, 1:] - pos[:, :, :, 0:-1] #  \n",
    "        #dif = torch.cat([dif.new(N, dif.size(1), V, 1).zero_(), dif], dim=-1)\n",
    "        \n",
    "        pos = self.joint_embed(pos)        \n",
    "        #dif = self.dif_embed(dif)\n",
    "        dy = pos #+ dif\n",
    "        #dy = dif\n",
    "        dy = dy.permute(0,1,3,2).contiguous() # N, C, T, V   \n",
    "        #print(dy.shape):torch.Size([1, 64, 300, 25])\n",
    "        #dy = self.attention(dy)\n",
    "        #dy.register_hook(lambda g: print(g))\n",
    "      \n",
    "        #########################\n",
    "        #out = self.tcn12(self.tcn11(self.sgcn1(dy)))\n",
    "        #out = self.tcn22(self.tcn21(self.sgcn2(out)))\n",
    "        #print(out.shape)\n",
    "        #out_channels = out.size(1)\n",
    "        #out = out.reshape(N, out_channels, -1)   \n",
    "        #print(out.shape)\n",
    "        #out = out.mean(2)\n",
    "        #print(out.shape)\n",
    "        #out = self.fc(out)\n",
    "        \n",
    "        out = self.sgcn1(dy)\n",
    "        print(out.size())\n",
    "        out = self.tcn11(out)\n",
    "        print(out.size())\n",
    "        out = self.tcn12(out)\n",
    "        print(out.size())\n",
    "        #out = self.tcn12(self.tcn11(self.sgcn1(dy)))\n",
    "        out = self.sgcn2(out)\n",
    "        print(out.size())\n",
    "        out = self.tcn21(out)\n",
    "        print(out.size())\n",
    "        out = self.tcn22(out)\n",
    "        print(out.size())\n",
    "        #out = self.tcn22(self.tcn21(self.sgcn2(out)))\n",
    "        #print(out.shape)\n",
    "        out_channels = out.size(1)\n",
    "        out = out.reshape(N, out_channels, -1)   \n",
    "        print(out.shape)\n",
    "        out = out.mean(2)\n",
    "        print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        print(out.size())\n",
    "        return out\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    !pip install thop\n",
    "    graph=adjGraph(layout='coco_cut',\n",
    "                 strategy='uniform',)\n",
    "    #graph=Graph()\n",
    "    # For debugging purposes\n",
    "#     cd /home/uniwa/students3/students/22905553/linux/phd_codes/Light_Fall\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "    import thop\n",
    "    from thop import clever_format\n",
    "     \n",
    "    model = Model(\n",
    "        num_class=2,\n",
    "        num_point=25,\n",
    "        max_frame=300,\n",
    "        #graph='graph.ntu_rgb_d.AdjMatrixGraph',\n",
    "        graph=graph,\n",
    "        act_type = 'relu',\n",
    "        bias = True,\n",
    "        edge = True,\n",
    "        block_size=41\n",
    "    )\n",
    "    #model = model.cuda()\n",
    "    macs, params = thop.profile(model, inputs=(torch.randn(32,2,300,14),), verbose=False)\n",
    "    macs, params = clever_format([macs, params], \"%.2f\")\n",
    "    #N, C, T, V, M = 6, 3, 300, 25, 2\n",
    "    \n",
    "#     x = torch.randn(1, 2, 300, 25)#.cuda()   \n",
    "#     out = model.forward(x)\n",
    "    \n",
    "#     ##\n",
    "#     # Drop frame\n",
    "#     import torch.nn.functional as F\n",
    "#     keep_prob = 0.9\n",
    "#     block_size = 41\n",
    "#     input = torch.randn(1,2,300,25)\n",
    "#     n,c,t,v = input.size()\n",
    "#     input1 = input.permute(0,1,3,2).contiguous().view(1,c*v,t)\n",
    "#     input_abs = torch.mean(torch.mean(torch.abs(input),dim=3),dim=1)\n",
    "#     gamma = (1. - keep_prob) / block_size\n",
    "#     M = torch.bernoulli(torch.clamp(input_abs * gamma, max=1.0)).repeat(1,c*v,1)\n",
    "#     Msum = F.max_pool1d(M, kernel_size=[block_size], stride=1, padding=block_size // 2)\n",
    "    \n",
    "#     mask = (1 - Msum)\n",
    "#     drop = (input1 * mask * mask.numel() /mask.sum()).view(n,c,v,t).permute(0,1,3,2)\n",
    "    \n",
    "#     idx = torch.randperm(Msum.shape[2])\n",
    "#     a = Msum[idx].view(Msum.size())\n",
    "    \n",
    "#     idx = torch.randperm(Msum.shape[2])\n",
    "#     a = Msum[:,:,idx].view(Msum.size())\n",
    "#     mask = (1 - a)\n",
    "#     drop = (input1 * mask * mask.numel() /mask.sum()).view(n,c,v,t).permute(0,1,3,2)\n",
    "    \n",
    "#     # Drop joints\n",
    "#     from utils import import_class\n",
    "#     input = torch.randn(1,2,300,25)\n",
    "#     n,c,t,v = input.size()\n",
    "#     #Graph = import_class('graph.ntu_rgb_d.AdjMatrixGraph')\n",
    "#     graph = Graph(**graph_args)\n",
    "#     A_binary = torch.Tensor(Graph().A_binary)\n",
    "#     input_abs = torch.mean(torch.mean(torch.abs(input), dim=2), dim=1)\n",
    "#     input_abs = input_abs / torch.sum(input_abs) * input_abs.numel()\n",
    "#     gamma = (1. - keep_prob) / (1 + 1.92)\n",
    "#     M_seed = torch.bernoulli(torch.clamp(input_abs * gamma, max=1.0))\n",
    "#     M = torch.matmul(M_seed, A_binary)\n",
    "#     M[M > 0.001] = 1.0\n",
    "#     M[M < 0.5] = 0.0\n",
    "#     mask = (1 - M).view(n, 1, 1, 25)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HyGUn8ubc-AL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = ['../Data/2clCoffee_01_new-set(labelXscrw).pkl',\n",
    "              '../Data/2clHome_01_new-set(labelXscrw).pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Fall','No_fall']\n",
    "num_class = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_files, batch_size, split_size=0.2):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            fts, lbs = pickle.load(f)\n",
    "            features.append(fts)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    if split_size > 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(features, labels, test_size=split_size,\n",
    "                                                              random_state=9)\n",
    "        train_set = data.TensorDataset(torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "                                       torch.tensor(y_train, dtype=torch.float32))\n",
    "        valid_set = data.TensorDataset(torch.tensor(x_valid, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "                                       torch.tensor(y_valid, dtype=torch.float32))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    else:\n",
    "        train_set = data.TensorDataset(torch.tensor(features, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "                                       torch.tensor(labels, dtype=torch.float32))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    save_folder = os.path.join(os.path.dirname(__file__), save_folder)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    # DATA.\n",
    "    train_loader, _ = load_dataset(data_files[0:1], batch_size) #batch_size = 32\n",
    "    \n",
    "    valid_loader, train_loader_ = load_dataset(data_files[:1], batch_size, 0.2)\n",
    "    #print(\"err\")\n",
    "    train_loader = data.DataLoader(data.ConcatDataset([train_loader.dataset, train_loader_.dataset]),\n",
    "                                   batch_size, shuffle=True)\n",
    "    dataloader = {'train': train_loader, 'valid': valid_loader}\n",
    "    del train_loader_\n",
    "    \n",
    "    #print(train_loader.shape)\n",
    "    \n",
    "    # MODEL.(list化)\n",
    "    graph_args = {'strategy': 'spatial'}\n",
    "    model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "    #model = TwoStreamSpatialTemporalGraph(graph_args, 8).to(device)\n",
    "\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "    #optimizer = Adadelta(model.parameters())\n",
    "    #optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "    \n",
    "    \n",
    "    losser = torch.nn.BCELoss() #fall or no_fall\n",
    "    #losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # TRAINING.\n",
    "    loss_list = {'train': [], 'valid': []}\n",
    "    accu_list = {'train': [], 'valid': []}\n",
    "    for e in range(epochs):\n",
    "        print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model = set_training(model, True)\n",
    "            else:\n",
    "                model = set_training(model, False)\n",
    "\n",
    "            run_loss = 0.0\n",
    "            run_accu = 0.0\n",
    "            with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "                for pts, lbs in iterator:\n",
    "                    # Create motion input by distance of points (x, y) of the same node\n",
    "                    # in two frames.\n",
    "                    mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "                    \n",
    "                    mot = mot.to(device)\n",
    "                    pts = pts.to(device)\n",
    "                    lbs = lbs.to(device)\n",
    "                    #print(pts.size())torch.Size([32, 3, 30, 14])\n",
    "                    #print(mot.size())torch.Size([32, 2, 29, 14])\n",
    "                    # Forward.\n",
    "                    out = model((pts, mot))\n",
    "                    #print(lbs)\n",
    "\n",
    "                    #print(out)\n",
    "                    loss = losser(out, lbs)#エラーが起きた\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Backward.\n",
    "                        model.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    run_loss += loss.item()\n",
    "                    accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                          lbs.detach().cpu().numpy())\n",
    "                    run_accu += accu\n",
    "\n",
    "                    iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                        loss.item(), accu))\n",
    "                    iterator.update()\n",
    "                    #break\n",
    "            loss_list[phase].append(run_loss / len(iterator))\n",
    "            accu_list[phase].append(run_accu / len(iterator))\n",
    "            #break\n",
    "\n",
    "        print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "              ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "                                             loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "\n",
    "        # SAVE.\n",
    "        torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model.pth'))\n",
    "        '''\n",
    "        plot_graphs(list(loss_list.values()), list(loss_list.keys()),\n",
    "                        'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                            loss_list['train'][-1], loss_list['valid'][-1]\n",
    "                        ), 'Loss', xlim=[0, epochs],\n",
    "                        save=os.path.join(save_folder, 'loss_graph.png'))\n",
    "        plot_graphs(list(accu_list.values()), list(accu_list.keys()),\n",
    "                        'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                            accu_list['train'][-1], accu_list['valid'][-1]\n",
    "                        ), 'Accu', xlim=[0, epochs],\n",
    "                        save=os.path.join(save_folder, 'accu_graph.png'))\n",
    "        '''\n",
    "            #break\n",
    "\n",
    "    del train_loader, valid_loader\n",
    "\n",
    "    #model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model.pth',map_location=torch.device('cpu'))))\n",
    "    model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model.pth')))\n",
    "    # EVALUATION.\n",
    "    model = set_training(model, False)\n",
    "    data_file = data_files[1]\n",
    "    eval_loader, _ = load_dataset([data_file], 32)\n",
    "    #data_file = data_files[2]\n",
    "    #eval_loader, _ = load_dataset([data_file], 64)\n",
    "\n",
    "    print('Evaluation.')\n",
    "    run_loss = 0.0\n",
    "    run_accu = 0.0\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    #with tqdm(eval_loader, desc='eval') as iterator:\n",
    "    #URFD\n",
    "    with tqdm(dataloader[phase], desc='eval') as iterator:\n",
    "        for pts, lbs in iterator:\n",
    "            mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "            mot = mot.to(device)\n",
    "            pts = pts.to(device)\n",
    "            lbs = lbs.to(device)\n",
    "\n",
    "            out = model((pts, mot))\n",
    "            loss = losser(out, lbs)\n",
    "\n",
    "            run_loss += loss.item()\n",
    "            accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                  lbs.detach().cpu().numpy())\n",
    "            run_accu += accu\n",
    "\n",
    "            y_preds.extend(out.argmax(1).detach().cpu().numpy())\n",
    "            y_trues.extend(lbs.argmax(1).cpu().numpy())\n",
    "\n",
    "            iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                loss.item(), accu))\n",
    "            iterator.update()\n",
    "\n",
    "    run_loss = run_loss / len(iterator)\n",
    "    run_accu = run_accu / len(iterator)\n",
    "\n",
    "    '''plot_confusion_metrix(y_trues, y_preds, class_names, 'Eval on: {}\\nLoss: {:.4f}, Accu{:.4f}'.format(\n",
    "        os.path.basename(data_file), run_loss, run_accu\n",
    "    ), 'true', save=os.path.join(save_folder, '{}-confusion_matrix.png'.format(\n",
    "        os.path.basename(data_file).split('.')[0])))\n",
    "        '''\n",
    "    print('Eval Loss: {:.4f}, Accu: {:.4f}'.format(run_loss, run_accu))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf29",
   "language": "python",
   "name": "tf29"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
